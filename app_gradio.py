import os
from typing import Dict, Tuple

import gradio as gr

from Model1_YellowOrange.train_eval import generate_caption_model1
from Model2_Transformer.train_eval import generate_caption_model2
from Original_Model.train_eval import generate_caption_original
from Model3_CNN_GRU.train_eval import generate_caption_cnn_gru
from Ex1_BLIP.blip_infer import generate_caption_blip


MODEL_CACHE: Dict[Tuple[str, str], object] = {}


def generate_caption(
    image,
    model_name: str,
    checkpoint: str,
):
    if image is None:
        return "è¯·å…ˆä¸Šä¼ å›¾ç‰‡ã€‚"

    # ä¿å­˜ä¸´æ—¶å›¾ç‰‡
    temp_path = "temp_input.jpg"
    image.save(temp_path)

    ckpt = checkpoint.strip() or None

    try:
        if model_name == "Model1":
            ckpt = ckpt or os.path.join(
                "data", "output", "weights", "model1_yelloworange.pth"
            )
            text = generate_caption_model1(temp_path, ckpt)
        elif model_name == "Model2":
            ckpt = ckpt or os.path.join("data", "output", "weights", "model2_transformer.pth")
            text = generate_caption_model2(temp_path, ckpt)
        elif model_name == "Original":
            ckpt = ckpt or os.path.join("data", "output", "weights", "original_model.pth")
            text = generate_caption_original(temp_path, ckpt)
        elif model_name == "CNN-GRU":
            ckpt = ckpt or os.path.join("data", "output", "weights", "cnn_gru.pth")
            text = generate_caption_cnn_gru(temp_path, ckpt)
        elif model_name == "BLIP":
            ckpt = ckpt or os.path.join("data", "output", "weights", "blip_finetuned.pth")
            text = generate_caption_blip(temp_path, ckpt)
        else:
            return "æœªçŸ¥æ¨¡å‹ç±»å‹ã€‚"
    except Exception as e:
        return f"æ¨ç†å‡ºé”™ï¼š{e}"

    return text


def launch():
    with gr.Blocks() as demo:
        # æ ‡é¢˜å’Œè¯´æ˜
        gr.Markdown(
            """
            # ğŸ–¼ï¸ å›¾åƒæè¿°ç”Ÿæˆç³»ç»Ÿ
            
            ä¸Šä¼ å›¾ç‰‡ï¼Œé€‰æ‹©æ¨¡å‹ï¼Œå³å¯è‡ªåŠ¨ç”Ÿæˆå›¾åƒæè¿°ã€‚æ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œå¯¹æ¯”ã€‚
            """
        )
        
        with gr.Row():
            with gr.Column(scale=1):
                # å›¾ç‰‡ä¸Šä¼ åŒºåŸŸï¼Œé™åˆ¶é«˜åº¦å¹¶ä¿æŒæ¯”ä¾‹
                img = gr.Image(
                    type="pil", 
                    label="ğŸ“¤ ä¸Šä¼ å›¾ç‰‡",
                    height=350,  # é™åˆ¶å›¾ç‰‡æ˜¾ç¤ºé«˜åº¦ï¼ˆåƒç´ ï¼‰ï¼Œä¿æŒå®½é«˜æ¯”
                    show_label=True,
                    container=True,
                )
                
                # æ¨¡å‹é€‰æ‹©ç§»åˆ°ä¸»åŒºåŸŸï¼Œæ›´å®¹æ˜“è®¿é—®
                model = gr.Dropdown(
                    ["Model1", "Model2", "Original", "CNN-GRU", "BLIP"],
                    value="Model1",
                    label="ğŸ¤– é€‰æ‹©æ¨¡å‹",
                    info="é€‰æ‹©ç”¨äºç”Ÿæˆæè¿°çš„æ¨¡å‹",
                )
                
                with gr.Accordion("âš™ï¸ é«˜çº§è®¾ç½®", open=False):
                    ckpt = gr.Textbox(
                        label="ğŸ“ Checkpoint è·¯å¾„ï¼ˆå¯é€‰ï¼‰",
                        placeholder="ç•™ç©ºä½¿ç”¨é»˜è®¤æ¨¡å‹æƒé‡",
                        value="",
                        info="å¦‚éœ€ä½¿ç”¨è‡ªå®šä¹‰è®­ç»ƒçš„æ¨¡å‹æƒé‡ï¼Œè¯·è¾“å…¥å®Œæ•´è·¯å¾„",
                    )
                
                # ç”ŸæˆæŒ‰é’®ï¼Œä½¿ç”¨ä¸»è¦æ ·å¼
                btn = gr.Button(
                    "ğŸš€ ç”Ÿæˆæè¿°", 
                    variant="primary",
                    size="lg",
                )
            
            with gr.Column(scale=1):
                # è¾“å‡ºåŒºåŸŸ
                output = gr.Textbox(
                    label="ğŸ“ ç”Ÿæˆçš„æè¿°",
                    lines=10,
                    placeholder="ç”Ÿæˆçš„å›¾åƒæè¿°å°†æ˜¾ç¤ºåœ¨è¿™é‡Œ...",
                    max_lines=15,
                )
                
                # æ¨¡å‹ä¿¡æ¯å±•ç¤ºåŒºåŸŸ
                with gr.Accordion("â„¹ï¸ æ¨¡å‹è¯´æ˜", open=False):
                    gr.Markdown(
                        """
                        **Model1 (YellowOrange)**: CNN + æ³¨æ„åŠ›æœºåˆ¶ + GRU  
                        **Model2 (Transformer)**: Transformer ç¼–ç å™¨-è§£ç å™¨æ¶æ„  
                        **Original**: åŸå§‹ CNN + ç®€å•æ³¨æ„åŠ› + GRU  
                        **CNN-GRU**: ResNet + GRU è§£ç å™¨  
                        **BLIP**: é¢„è®­ç»ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹
                        """
                    )

        # ç»‘å®šäº‹ä»¶
        btn.click(
            fn=generate_caption,
            inputs=[img, model, ckpt],
            outputs=[output],
        )
        
        # æ·»åŠ ç¤ºä¾‹è¯´æ˜
        gr.Markdown(
            """
            ---
            ### ğŸ’¡ ä½¿ç”¨æç¤º
            - æ”¯æŒå¸¸è§å›¾ç‰‡æ ¼å¼ï¼ˆJPGã€PNGã€JPEGç­‰ï¼‰
            - å›¾ç‰‡ä¼šè‡ªåŠ¨è°ƒæ•´åˆ°åˆé€‚å¤§å°æ˜¾ç¤º
            - ä¸åŒæ¨¡å‹å¯èƒ½ç”Ÿæˆä¸åŒé£æ ¼çš„æè¿°ï¼Œå¯ä»¥å°è¯•å¤šä¸ªæ¨¡å‹å¯¹æ¯”
            """
        )

    demo.launch(share=False, theme=gr.themes.Soft())


if __name__ == "__main__":
    launch()


